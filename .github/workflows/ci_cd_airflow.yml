name: Trigger Airflow DAG on Branch

# Trigger the workflow when there's a push to the "main" branch
on:
  push:
    branches:
      - main  # Workflow is triggered on a push to the "main" branch

# Define jobs in the workflow
jobs:
  trigger_dag:
    runs-on: ubuntu-latest  # Define the base operating system
    
    # Define the steps for the job
    steps:
      # Step 1: Check out the repository codebase
      - name: Checkout code
        uses: actions/checkout@v4
      
      # Step 2: Validate the DAG structure or other checks
      - name: Validate DAG
        run: |
          # Perform DAG validation, e.g., syntax check or other checks
          echo "Validating the DAG..."

      # Step 3: Trigger the Airflow DAG
      - name: Trigger Airflow DAG
        run: |
          #w8 40 sec to let git-sync fetch changes
          sleep 40
          
          # Make a request to trigger the DAG in Airflow
          # Use GitHub Secrets to secure sensitive information

          response=$(curl -G -X GET "${{secrets.AIRFLOW_API_URL_RUN_DAG}}" \
              --data-urlencode "dag_name=sales_data_extraction" \
              --data-urlencode "username=${{secrets.AIRFLOW_USERNAME}}" \
              --data-urlencode "password=${{secrets.AIRFLOW_PASSWORD}}" \
              -H "x-api-key: ${{secrets.AIRFLOW_TOKEN}}" )

          dag_id=$(echo $response | jq -r '.dag_id')
          dag_run_id=$(echo $response | jq -r '.dag_run_id')
          echo $dag_id was started

          echo "dag_id=$dag_id" >> $GITHUB_ENV
          echo "dag_run_id=$dag_run_id" >> $GITHUB_ENV


      # Step 4: Trigger the Airflow DAG
      - name: Check Airflow DAG status
        run: |
          # Initialize the status variable
          dag_status=""
      
          # Loop until the dag_status is 'success'
          until [[ "$dag_status" == "success" ]]; do
            # Pause between checks to avoid rate limiting or excessive load
            echo "Waiting for DAG to complete..."
            sleep 60  # Wait for 60 seconds before checking again
      
            # Make the API request and update dag_status
            dag_status=$(curl -G -X GET "${{ secrets.AIRFLOW_API_URL_CHECK_DAG_STATUS }}" \
              --data-urlencode "dag_name=${{ env.dag_id }}" \
              --data-urlencode "dag_run_id=${{ env.dag_run_id }}" \
              --data-urlencode "username=${{ secrets.AIRFLOW_USERNAME }}" \
              --data-urlencode "password=${{ secrets.AIRFLOW_PASSWORD }}" \
              -H "x-api-key: ${{ secrets.AIRFLOW_TOKEN }}" | jq -r '.dag_status')
            
            # Log current status
            echo "Current DAG status: $dag_status"
            if [ "$dag_status" = "success" ]; then
              echo "DAG succeeded"
            else
              echo "DAG failed"
              exit 1  # Exit with non-zero status to indicate failure
            fi
          done
      
          # Final status message
          echo "DAG has successfully completed: $dag_status"


          
      
   
